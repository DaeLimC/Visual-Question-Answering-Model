# Visual-Question-Answering-Model

The model that takes a question and an image as input, and returns a yes/no answer in response. 

The starter dataset contains all the "yes" / "no" questions from the VQA v2 training annotations.
The answers are the most frequent one to the question (ties broken randomly).
There are 20,000 question / image pairs.
Each image and question is used exactly once.
The image filenames correspond to the COCO 2014 training images.

Preprocessed dataset was hosted on a personal cloud for usage. 
